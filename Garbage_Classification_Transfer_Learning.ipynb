{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage Classification using Transfer Learning\n",
    "\n",
    "This notebook demonstrates how to classify garbage images into categories using transfer learning with a pre-trained convolutional neural network.\n",
    "\n",
    "Dataset: [Garbage Classification dataset on Kaggle](https://www.kaggle.com/datasets/mostafaabla/garbage-classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install Kaggle if not already installed\n",
    "!pip install -q kaggle\n",
    "# Usual imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Prepare Dataset\n",
    "\n",
    "**Note:** This notebook does not include the dataset. Please download it from Kaggle using the following commands."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Download from Kaggle (uncomment and run if not done already)\n",
    "# !kaggle datasets download mostafaabla/garbage-classification\n",
    "# !unzip garbage-classification.zip -d data/\n",
    "\n",
    "# Set data directory\n",
    "DATA_DIR = './data/Garbage classification/'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "classes = os.listdir(DATA_DIR)\n",
    "print('Classes:', classes)\n",
    "\n",
    "# Show sample images\n",
    "plt.figure(figsize=(15,8))\n",
    "for idx, cls in enumerate(classes):\n",
    "    img_path = glob.glob(os.path.join(DATA_DIR, cls, '*.jpg'))[0]\n",
    "    img = Image.open(img_path)\n",
    "    plt.subplot(2, 4, idx+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(cls)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation (ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Model Using Transfer Learning (MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plotting accuracy and loss\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {val_acc:.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get predictions and true labels\n",
    "val_generator.reset()\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = val_generator.classes\n",
    "labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes, target_names=labels))\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(np.arange(len(labels)), labels, rotation=45)\n",
    "plt.yticks(np.arange(len(labels)), labels)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Making Predictions on New Images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def predict_image(img_path):\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    preds = model.predict(img_array)\n",
    "    class_idx = np.argmax(preds)\n",
    "    class_label = labels[class_idx]\n",
    "    confidence = preds[0][class_idx]\n",
    "    print(f\"Prediction: {class_label} (Confidence: {confidence*100:.2f}%)\")\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {class_label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# predict_image('path/to/your/image.jpg')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes\n",
    "- Make sure to download the dataset using Kaggle CLI as described above.\n",
    "- Tune hyperparameters and try different pre-trained models for better results.\n",
    "- If you use this notebook, please cite the original dataset and acknowledge sources as appropriate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}